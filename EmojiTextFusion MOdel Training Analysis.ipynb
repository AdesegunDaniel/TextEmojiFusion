{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: afinn in c:\\users\\owner\\anaconda3\\lib\\site-packages (0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "from afinn import Afinn\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python -V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'/kaggle/input/spicy-dataset/Emoji_Dataset.csv')\n",
    "with open('/kaggle/input/spicy-dataset/Sentiment Group.json', 'r') as file:\n",
    "    groups=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='https://tfhub.dev/google/elmo/3'\n",
    "def Embedding(sentence, batch_size=5000, model_path=path, key='elmo'):\n",
    "    tf_sent=tf.stack([tf.constant(x) for x in sentence], axis=0)\n",
    "    embed= hub.KerasLayer(model_path, output_key=key, trainable=False)\n",
    "    result=[]\n",
    "    count=1\n",
    "    for start in range(0, len(tf_sent), batch_size):\n",
    "        end=start+batch_size  \n",
    "        embed_sent=embed(tf_sent[start:end])\n",
    "        result.extend(embed_sent)\n",
    "        print(f\"embedding sentences batch{count} done batch{count+1} processing......\")\n",
    "        count+=1\n",
    "    return tf.stack(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:35:03.667222Z",
     "iopub.status.busy": "2024-09-03T10:35:03.666498Z",
     "iopub.status.idle": "2024-09-03T10:35:03.673216Z",
     "shell.execute_reply": "2024-09-03T10:35:03.672078Z",
     "shell.execute_reply.started": "2024-09-03T10:35:03.667185Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify(sentence):\n",
    "    model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    afn=Afinn()\n",
    "    score=afn.score(sentence)\n",
    "    sentiment= 1 if score > 0 else 1 if score < 0 else 2\n",
    "    if sentiment== 2:\n",
    "        return sentiment\n",
    "    if sentiment == 1:\n",
    "        sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model_name, device=0)\n",
    "        label=sentiment_analyzer(sentence)[0]['label']\n",
    "        sentiment= 1 if label =='POSITIVE' else 0\n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:35:17.847006Z",
     "iopub.status.busy": "2024-09-03T10:35:17.846636Z",
     "iopub.status.idle": "2024-09-03T10:35:17.870453Z",
     "shell.execute_reply": "2024-09-03T10:35:17.869526Z",
     "shell.execute_reply.started": "2024-09-03T10:35:17.846978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ðŸ¤©</td>\n",
       "      <td>star-struck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ðŸ’€</td>\n",
       "      <td>skull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸ‘¹</td>\n",
       "      <td>ogre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ðŸ‘º</td>\n",
       "      <td>goblin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ‘»</td>\n",
       "      <td>ghost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji         name\n",
       "0     ðŸ¤©  star-struck\n",
       "1     ðŸ’€        skull\n",
       "2     ðŸ‘¹         ogre\n",
       "3     ðŸ‘º       goblin\n",
       "4     ðŸ‘»        ghost"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive=pd.DataFrame(groups['POSITIVE'])\n",
    "negative=pd.DataFrame(groups['NEGATIVE'])\n",
    "neutral=pd.DataFrame(groups['NEUTRAL'])\n",
    "object_=pd.DataFrame(groups['OBJECT'])\n",
    "object_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:35:37.651461Z",
     "iopub.status.busy": "2024-09-03T10:35:37.651053Z",
     "iopub.status.idle": "2024-09-03T10:35:37.659377Z",
     "shell.execute_reply": "2024-09-03T10:35:37.658434Z",
     "shell.execute_reply.started": "2024-09-03T10:35:37.651430Z"
    }
   },
   "outputs": [],
   "source": [
    "def single_embed(sentence):\n",
    "    new=[]\n",
    "    for sent in sentence:\n",
    "        n_sent=sent.split()\n",
    "        while len(n_sent)>6:\n",
    "            sen=n_sent[:6]\n",
    "            new.append(' '.join(sen))\n",
    "            n_sent=sent[6:]\n",
    "        if len(n_sent)!=0:\n",
    "            new.append(' '.join(n_sent))\n",
    "    embed=Embedding(new)\n",
    "    result=[]\n",
    "    for em in embed:\n",
    "        if em.shape[0]!=6:\n",
    "            p=6-em.shape[0]\n",
    "            pad_em=np.pad(em,((0,p),(0,0)))\n",
    "            result.append(tf.constant(pad_em))\n",
    "        else:\n",
    "            result.append(em)\n",
    "            \n",
    "    return tf.stack(result)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:35:41.270064Z",
     "iopub.status.busy": "2024-09-03T10:35:41.269711Z",
     "iopub.status.idle": "2024-09-03T10:36:00.291154Z",
     "shell.execute_reply": "2024-09-03T10:36:00.290174Z",
     "shell.execute_reply.started": "2024-09-03T10:35:41.270036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding sentences batch1 done batch2 processing......\n",
      "embedding sentences batch1 done batch2 processing......\n",
      "embedding sentences batch1 done batch2 processing......\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(58, 6, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_arr=single_embed(list(positive['name'])).numpy()\n",
    "neg_arr=single_embed(list(negative['name'])).numpy()\n",
    "neu_arr=single_embed(list(neutral['name'])).numpy()\n",
    "neu_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:44:53.944951Z",
     "iopub.status.busy": "2024-09-03T10:44:53.944573Z",
     "iopub.status.idle": "2024-09-03T10:44:53.955107Z",
     "shell.execute_reply": "2024-09-03T10:44:53.954350Z",
     "shell.execute_reply.started": "2024-09-03T10:44:53.944920Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "standard_array={'pos_arr':pos_arr, 'neg_arr':neg_arr, 'neu_arr':neu_arr}\n",
    "\n",
    "\n",
    "with open('Standard Array.pkl', 'wb') as file:\n",
    "    pickle.dump(standard_array, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:53:50.651280Z",
     "iopub.status.busy": "2024-09-03T10:53:50.650625Z",
     "iopub.status.idle": "2024-09-03T10:53:50.659968Z",
     "shell.execute_reply": "2024-09-03T10:53:50.658970Z",
     "shell.execute_reply.started": "2024-09-03T10:53:50.651246Z"
    }
   },
   "outputs": [],
   "source": [
    "obj_dic={name:emoji for name, emoji in zip(list(object_['name']),list(object_['emoji']))}\n",
    "pos_dic={idx:emoji for idx, emoji in enumerate(list(positive['emoji']))}\n",
    "neg_dic={idx:emoji for idx, emoji in enumerate(list(negative['emoji']))}\n",
    "neu_dic={idx:emoji for idx, emoji in enumerate(list(neutral['emoji']))}\n",
    "decode={0:'Negative', 1:'Positive', 2:'Neutral'}\n",
    "\n",
    "Ref_dic={'obj_dic':obj_dic, 'pos_dic':pos_dic, 'neg_dic':neg_dic, 'neu_dic':neu_dic, 'decode':decode}\n",
    "\n",
    "with open('Ref_dic.pkl', 'wb') as file:\n",
    "    pickle.dump(Ref_dic, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:54:48.507878Z",
     "iopub.status.busy": "2024-09-03T10:54:48.507535Z",
     "iopub.status.idle": "2024-09-03T10:54:48.524439Z",
     "shell.execute_reply": "2024-09-03T10:54:48.523394Z",
     "shell.execute_reply.started": "2024-09-03T10:54:48.507853Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract(sent_arr, group):\n",
    "    if group==0:\n",
    "        emo= np.argsort(euclidean_distances(neg_arr.reshape(neg_arr.shape[0],-1), \n",
    "                                          sent_arr.reshape(1,-1)), axis=0).reshape(1,-1)[0][:20]\n",
    "        emoji=neg_dic[np.random.choice(emo)]\n",
    "    elif group==1:\n",
    "        emo= np.argsort(euclidean_distances(pos_arr.reshape(pos_arr.shape[0], -1),\n",
    "                                          sent_arr.reshape(1,-1)), axis=0).reshape(1,-1)[0][:20]\n",
    "        emoji=pos_dic[np.random.choice(emo)]\n",
    "        \n",
    "    else:\n",
    "        emo=np.argsort(euclidean_distances(neu_arr.reshape(neu_arr.shape[0], -1),\n",
    "                                        sent_arr.reshape(1,-1)), axis=0).reshape(1,-1)[0][:20]\n",
    "        emoji=neu_dic[np.random.choice(emo)]        \n",
    "    \n",
    "    return emoji\n",
    "\n",
    "\n",
    "def predict(sentences):\n",
    "    prediction=[]\n",
    "    for sentence in sentences:\n",
    "        sent=sentence.split()\n",
    "        work=[]\n",
    "        while len(sent)>6:\n",
    "            wrk=sent[:6]\n",
    "            work.append(' '.join(wrk))\n",
    "            sent=sent[6:]\n",
    "        if sent!=0:\n",
    "            work.append(' '.join(sent))\n",
    "    \n",
    "        embed=Embedding(work).numpy()\n",
    "        if embed.shape[1]!=6:\n",
    "            p=6-embed.shape[1]\n",
    "            embed=np.pad(embed,((0,0),(0,p),(0,0)))\n",
    "            \n",
    "        grp=[classify(x) for x in work]\n",
    "        grp_emo=[extract(arr,group) for arr,group in zip(embed,grp)]\n",
    "        result=' '.join([x+' '+re.sub(r'\\u200d','',y) for x,y in zip(work,grp_emo)]).split()\n",
    "        \n",
    "        \n",
    "        for i,x in enumerate(result):\n",
    "            if x in obj_dic.keys():\n",
    "                result[i]=x+obj_dic[x]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        prediction.append([' '.join(result), decode[grp[0]]])\n",
    "    return  prediction, \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T11:58:11.313736Z",
     "iopub.status.busy": "2024-09-03T11:58:11.313040Z",
     "iopub.status.idle": "2024-09-03T11:58:11.327997Z",
     "shell.execute_reply": "2024-09-03T11:58:11.327125Z",
     "shell.execute_reply.started": "2024-09-03T11:58:11.313703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"is a powerful and intuitive tool designed to enhance your text with the perfect emojis. Whether you're looking to add a touch of emotion, humor, or emphasis, TextEmojiFusion is not just a tool; it's your creative partner in the digital realm, transforming mundane messages into vibrant conversations. Imagine a platform that understands the nuances of your emotions and the subtleties of your humor, then curates a selection of emojis that perfectly align with your intent. TextEmojiFusion does just that, bridging the gap between plain text and the rich expressiveness of emojis. With its intuitive design, it's incredibly user-friendly, inviting you to elevate your communication effortlessly. Whether you're conveying heartfelt sentiments, injecting a dose of wit, or emphasizing key points, TextEmojiFusion integrates emojis with such finesse that your messages will capture hearts and imaginations alike. It's not merely about enhancing text; it's about enriching connections and sharing experiences that words alone can't fully express. With TextEmojiFusion, every message becomes a canvas, and every conversation is an opportunity to create something memorable. So why settle for ordinary when you can communicate with color, emotion, and life? Embrace the power of TextEmojiFusion and watch your digital interactions blossom into engaging, expressive, and extraordinary exchanges.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"is a powerful and intuitive tool designed to enhance your text with the perfect emojis. Whether you're looking to add a touch of emotion, humor, or emphasis, TextEmojiFusion is not just a tool; it's your creative partner in the digital realm, transforming mundane messages into vibrant conversations. Imagine a platform that understands the nuances of your emotions and the subtleties of your humor, then curates a selection of emojis that perfectly align with your intent. TextEmojiFusion does just that, bridging the gap between plain text and the rich expressiveness of emojis. With its intuitive design, it's incredibly user-friendly, inviting you to elevate your communication effortlessly. Whether you're conveying heartfelt sentiments, injecting a dose of wit, or emphasizing key points, TextEmojiFusion integrates emojis with such finesse that your messages will capture hearts and imaginations alike. It's not merely about enhancing text; it's about enriching connections and sharing experiences that words alone can't fully express. With TextEmojiFusion, every message becomes a canvas, and every conversation is an opportunity to create something memorable. So why settle for ordinary when you can communicate with color, emotion, and life? Embrace the power of TextEmojiFusion and watch your digital interactions blossom into engaging, expressive, and extraordinary exchanges.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:54:53.677959Z",
     "iopub.status.busy": "2024-09-03T10:54:53.677185Z",
     "iopub.status.idle": "2024-09-03T10:55:06.277318Z",
     "shell.execute_reply": "2024-09-03T10:55:06.276166Z",
     "shell.execute_reply.started": "2024-09-03T10:54:53.677927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding sentences batch1 done batch2 processing......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a623deeeaf49758ed346179121f917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c2a5667cef40bda45b16b07e20acd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cffbcb27dc4ebda18116c8d0db3054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21618915de2647b18b61754d8ed39955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([[\"is a powerful and intuitive tool ðŸ™ƒ designed to enhance your text with ðŸ™Š the perfect emojis. Whether you're looking ðŸ’Œ to add a touch of emotion, ðŸ’­ humor, or emphasis, TextEmojiFusion is not ðŸ¤¤ just a tool; it's your creative ðŸ™ƒ partner in the digital realm, transforming ðŸ˜º mundane messages into vibrant conversations. Imagine ðŸ¤— a platform that understands the nuances ðŸ§” of your emotions and the subtleties ðŸ¦¾ of your humor, then curates a ðŸ˜— selection of emojis that perfectly align ðŸ˜— with your intent. TextEmojiFusion does just ðŸ¤ that, bridging the gap between plain ðŸ¤ž text and the rich expressiveness of ðŸ˜€ emojis. With its intuitive design, it's ðŸ˜½ incredibly user-friendly, inviting you to elevate â˜º your communication effortlessly. Whether you're conveying ðŸ¤“ heartfelt sentiments, injecting a dose of ðŸ˜‰ wit, or emphasizing keyðŸ”‘ points, TextEmojiFusion ðŸ™ˆ integrates emojis with such finesse that ðŸ™ your messages will capture hearts and ðŸ‘¾ imaginations alike. It's not merely about ðŸ˜º enhancing text; it's about enriching connections ðŸ’ª and sharing experiences that words alone ðŸ˜‹ can't fully express. With TextEmojiFusion, every ðŸ¦¿ message becomes a canvas, and every ðŸ’­ conversation is an opportunity to create ðŸ˜‰ something memorable. So why settle for ðŸ’“ ordinary when you can communicate with ðŸ˜¾ color, emotion, and life? Embrace the ðŸ˜‰ power of TextEmojiFusion and watchâŒš your ðŸ’© digital interactions blossomðŸŒ¼ into engaging, expressive, ðŸ˜¾ and extraordinary exchanges. ðŸ˜½\",\n",
       "   'Positive']],)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spicy=predict([text])\n",
    "spicy"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5529204,
     "sourceId": 9252735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
