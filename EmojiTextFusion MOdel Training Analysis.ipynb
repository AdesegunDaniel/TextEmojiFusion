{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: afinn in c:\\users\\owner\\anaconda3\\lib\\site-packages (0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "from afinn import Afinn\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python -V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'/kaggle/input/spicy-dataset/Emoji_Dataset.csv')\n",
    "with open('/kaggle/input/spicy-dataset/Sentiment Group.json', 'r') as file:\n",
    "    groups=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='https://tfhub.dev/google/elmo/3'\n",
    "def Embedding(sentence, batch_size=5000, model_path=path, key='elmo'):\n",
    "    tf_sent=tf.stack([tf.constant(x) for x in sentence], axis=0)\n",
    "    embed= hub.KerasLayer(model_path, output_key=key, trainable=False)\n",
    "    result=[]\n",
    "    count=1\n",
    "    for start in range(0, len(tf_sent), batch_size):\n",
    "        end=start+batch_size  \n",
    "        embed_sent=embed(tf_sent[start:end])\n",
    "        result.extend(embed_sent)\n",
    "        print(f\"embedding sentences batch{count} done batch{count+1} processing......\")\n",
    "        count+=1\n",
    "    return tf.stack(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:35:03.667222Z",
     "iopub.status.busy": "2024-09-03T10:35:03.666498Z",
     "iopub.status.idle": "2024-09-03T10:35:03.673216Z",
     "shell.execute_reply": "2024-09-03T10:35:03.672078Z",
     "shell.execute_reply.started": "2024-09-03T10:35:03.667185Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify(sentence):\n",
    "    model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    afn=Afinn()\n",
    "    score=afn.score(sentence)\n",
    "    sentiment= 1 if score > 0 else 1 if score < 0 else 2\n",
    "    if sentiment== 2:\n",
    "        return sentiment\n",
    "    if sentiment == 1:\n",
    "        sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model_name, device=0)\n",
    "        label=sentiment_analyzer(sentence)[0]['label']\n",
    "        sentiment= 1 if label =='POSITIVE' else 0\n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:35:17.847006Z",
     "iopub.status.busy": "2024-09-03T10:35:17.846636Z",
     "iopub.status.idle": "2024-09-03T10:35:17.870453Z",
     "shell.execute_reply": "2024-09-03T10:35:17.869526Z",
     "shell.execute_reply.started": "2024-09-03T10:35:17.846978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤩</td>\n",
       "      <td>star-struck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>💀</td>\n",
       "      <td>skull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>👹</td>\n",
       "      <td>ogre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>👺</td>\n",
       "      <td>goblin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>👻</td>\n",
       "      <td>ghost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji         name\n",
       "0     🤩  star-struck\n",
       "1     💀        skull\n",
       "2     👹         ogre\n",
       "3     👺       goblin\n",
       "4     👻        ghost"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive=pd.DataFrame(groups['POSITIVE'])\n",
    "negative=pd.DataFrame(groups['NEGATIVE'])\n",
    "neutral=pd.DataFrame(groups['NEUTRAL'])\n",
    "object_=pd.DataFrame(groups['OBJECT'])\n",
    "object_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:35:37.651461Z",
     "iopub.status.busy": "2024-09-03T10:35:37.651053Z",
     "iopub.status.idle": "2024-09-03T10:35:37.659377Z",
     "shell.execute_reply": "2024-09-03T10:35:37.658434Z",
     "shell.execute_reply.started": "2024-09-03T10:35:37.651430Z"
    }
   },
   "outputs": [],
   "source": [
    "def single_embed(sentence):\n",
    "    new=[]\n",
    "    for sent in sentence:\n",
    "        n_sent=sent.split()\n",
    "        while len(n_sent)>6:\n",
    "            sen=n_sent[:6]\n",
    "            new.append(' '.join(sen))\n",
    "            n_sent=sent[6:]\n",
    "        if len(n_sent)!=0:\n",
    "            new.append(' '.join(n_sent))\n",
    "    embed=Embedding(new)\n",
    "    result=[]\n",
    "    for em in embed:\n",
    "        if em.shape[0]!=6:\n",
    "            p=6-em.shape[0]\n",
    "            pad_em=np.pad(em,((0,p),(0,0)))\n",
    "            result.append(tf.constant(pad_em))\n",
    "        else:\n",
    "            result.append(em)\n",
    "            \n",
    "    return tf.stack(result)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:35:41.270064Z",
     "iopub.status.busy": "2024-09-03T10:35:41.269711Z",
     "iopub.status.idle": "2024-09-03T10:36:00.291154Z",
     "shell.execute_reply": "2024-09-03T10:36:00.290174Z",
     "shell.execute_reply.started": "2024-09-03T10:35:41.270036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding sentences batch1 done batch2 processing......\n",
      "embedding sentences batch1 done batch2 processing......\n",
      "embedding sentences batch1 done batch2 processing......\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(58, 6, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_arr=single_embed(list(positive['name'])).numpy()\n",
    "neg_arr=single_embed(list(negative['name'])).numpy()\n",
    "neu_arr=single_embed(list(neutral['name'])).numpy()\n",
    "neu_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:44:53.944951Z",
     "iopub.status.busy": "2024-09-03T10:44:53.944573Z",
     "iopub.status.idle": "2024-09-03T10:44:53.955107Z",
     "shell.execute_reply": "2024-09-03T10:44:53.954350Z",
     "shell.execute_reply.started": "2024-09-03T10:44:53.944920Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "standard_array={'pos_arr':pos_arr, 'neg_arr':neg_arr, 'neu_arr':neu_arr}\n",
    "\n",
    "\n",
    "with open('Standard Array.pkl', 'wb') as file:\n",
    "    pickle.dump(standard_array, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:53:50.651280Z",
     "iopub.status.busy": "2024-09-03T10:53:50.650625Z",
     "iopub.status.idle": "2024-09-03T10:53:50.659968Z",
     "shell.execute_reply": "2024-09-03T10:53:50.658970Z",
     "shell.execute_reply.started": "2024-09-03T10:53:50.651246Z"
    }
   },
   "outputs": [],
   "source": [
    "obj_dic={name:emoji for name, emoji in zip(list(object_['name']),list(object_['emoji']))}\n",
    "pos_dic={idx:emoji for idx, emoji in enumerate(list(positive['emoji']))}\n",
    "neg_dic={idx:emoji for idx, emoji in enumerate(list(negative['emoji']))}\n",
    "neu_dic={idx:emoji for idx, emoji in enumerate(list(neutral['emoji']))}\n",
    "decode={0:'Negative', 1:'Positive', 2:'Neutral'}\n",
    "\n",
    "Ref_dic={'obj_dic':obj_dic, 'pos_dic':pos_dic, 'neg_dic':neg_dic, 'neu_dic':neu_dic, 'decode':decode}\n",
    "\n",
    "with open('Ref_dic.pkl', 'wb') as file:\n",
    "    pickle.dump(Ref_dic, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:54:48.507878Z",
     "iopub.status.busy": "2024-09-03T10:54:48.507535Z",
     "iopub.status.idle": "2024-09-03T10:54:48.524439Z",
     "shell.execute_reply": "2024-09-03T10:54:48.523394Z",
     "shell.execute_reply.started": "2024-09-03T10:54:48.507853Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract(sent_arr, group):\n",
    "    if group==0:\n",
    "        emo= np.argsort(euclidean_distances(neg_arr.reshape(neg_arr.shape[0],-1), \n",
    "                                          sent_arr.reshape(1,-1)), axis=0).reshape(1,-1)[0][:20]\n",
    "        emoji=neg_dic[np.random.choice(emo)]\n",
    "    elif group==1:\n",
    "        emo= np.argsort(euclidean_distances(pos_arr.reshape(pos_arr.shape[0], -1),\n",
    "                                          sent_arr.reshape(1,-1)), axis=0).reshape(1,-1)[0][:20]\n",
    "        emoji=pos_dic[np.random.choice(emo)]\n",
    "        \n",
    "    else:\n",
    "        emo=np.argsort(euclidean_distances(neu_arr.reshape(neu_arr.shape[0], -1),\n",
    "                                        sent_arr.reshape(1,-1)), axis=0).reshape(1,-1)[0][:20]\n",
    "        emoji=neu_dic[np.random.choice(emo)]        \n",
    "    \n",
    "    return emoji\n",
    "\n",
    "\n",
    "def predict(sentences):\n",
    "    prediction=[]\n",
    "    for sentence in sentences:\n",
    "        sent=sentence.split()\n",
    "        work=[]\n",
    "        while len(sent)>6:\n",
    "            wrk=sent[:6]\n",
    "            work.append(' '.join(wrk))\n",
    "            sent=sent[6:]\n",
    "        if sent!=0:\n",
    "            work.append(' '.join(sent))\n",
    "    \n",
    "        embed=Embedding(work).numpy()\n",
    "        if embed.shape[1]!=6:\n",
    "            p=6-embed.shape[1]\n",
    "            embed=np.pad(embed,((0,0),(0,p),(0,0)))\n",
    "            \n",
    "        grp=[classify(x) for x in work]\n",
    "        grp_emo=[extract(arr,group) for arr,group in zip(embed,grp)]\n",
    "        result=' '.join([x+' '+re.sub(r'\\u200d','',y) for x,y in zip(work,grp_emo)]).split()\n",
    "        \n",
    "        \n",
    "        for i,x in enumerate(result):\n",
    "            if x in obj_dic.keys():\n",
    "                result[i]=x+obj_dic[x]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        prediction.append([' '.join(result), decode[grp[0]]])\n",
    "    return  prediction, \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T11:58:11.313736Z",
     "iopub.status.busy": "2024-09-03T11:58:11.313040Z",
     "iopub.status.idle": "2024-09-03T11:58:11.327997Z",
     "shell.execute_reply": "2024-09-03T11:58:11.327125Z",
     "shell.execute_reply.started": "2024-09-03T11:58:11.313703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"is a powerful and intuitive tool designed to enhance your text with the perfect emojis. Whether you're looking to add a touch of emotion, humor, or emphasis, TextEmojiFusion is not just a tool; it's your creative partner in the digital realm, transforming mundane messages into vibrant conversations. Imagine a platform that understands the nuances of your emotions and the subtleties of your humor, then curates a selection of emojis that perfectly align with your intent. TextEmojiFusion does just that, bridging the gap between plain text and the rich expressiveness of emojis. With its intuitive design, it's incredibly user-friendly, inviting you to elevate your communication effortlessly. Whether you're conveying heartfelt sentiments, injecting a dose of wit, or emphasizing key points, TextEmojiFusion integrates emojis with such finesse that your messages will capture hearts and imaginations alike. It's not merely about enhancing text; it's about enriching connections and sharing experiences that words alone can't fully express. With TextEmojiFusion, every message becomes a canvas, and every conversation is an opportunity to create something memorable. So why settle for ordinary when you can communicate with color, emotion, and life? Embrace the power of TextEmojiFusion and watch your digital interactions blossom into engaging, expressive, and extraordinary exchanges.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"is a powerful and intuitive tool designed to enhance your text with the perfect emojis. Whether you're looking to add a touch of emotion, humor, or emphasis, TextEmojiFusion is not just a tool; it's your creative partner in the digital realm, transforming mundane messages into vibrant conversations. Imagine a platform that understands the nuances of your emotions and the subtleties of your humor, then curates a selection of emojis that perfectly align with your intent. TextEmojiFusion does just that, bridging the gap between plain text and the rich expressiveness of emojis. With its intuitive design, it's incredibly user-friendly, inviting you to elevate your communication effortlessly. Whether you're conveying heartfelt sentiments, injecting a dose of wit, or emphasizing key points, TextEmojiFusion integrates emojis with such finesse that your messages will capture hearts and imaginations alike. It's not merely about enhancing text; it's about enriching connections and sharing experiences that words alone can't fully express. With TextEmojiFusion, every message becomes a canvas, and every conversation is an opportunity to create something memorable. So why settle for ordinary when you can communicate with color, emotion, and life? Embrace the power of TextEmojiFusion and watch your digital interactions blossom into engaging, expressive, and extraordinary exchanges.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:54:53.677959Z",
     "iopub.status.busy": "2024-09-03T10:54:53.677185Z",
     "iopub.status.idle": "2024-09-03T10:55:06.277318Z",
     "shell.execute_reply": "2024-09-03T10:55:06.276166Z",
     "shell.execute_reply.started": "2024-09-03T10:54:53.677927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding sentences batch1 done batch2 processing......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a623deeeaf49758ed346179121f917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c2a5667cef40bda45b16b07e20acd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cffbcb27dc4ebda18116c8d0db3054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21618915de2647b18b61754d8ed39955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([[\"is a powerful and intuitive tool 🙃 designed to enhance your text with 🙊 the perfect emojis. Whether you're looking 💌 to add a touch of emotion, 💭 humor, or emphasis, TextEmojiFusion is not 🤤 just a tool; it's your creative 🙃 partner in the digital realm, transforming 😺 mundane messages into vibrant conversations. Imagine 🤗 a platform that understands the nuances 🧔 of your emotions and the subtleties 🦾 of your humor, then curates a 😗 selection of emojis that perfectly align 😗 with your intent. TextEmojiFusion does just 🤏 that, bridging the gap between plain 🤞 text and the rich expressiveness of 😀 emojis. With its intuitive design, it's 😽 incredibly user-friendly, inviting you to elevate ☺ your communication effortlessly. Whether you're conveying 🤓 heartfelt sentiments, injecting a dose of 😉 wit, or emphasizing key🔑 points, TextEmojiFusion 🙈 integrates emojis with such finesse that 🙏 your messages will capture hearts and 👾 imaginations alike. It's not merely about 😺 enhancing text; it's about enriching connections 💪 and sharing experiences that words alone 😋 can't fully express. With TextEmojiFusion, every 🦿 message becomes a canvas, and every 💭 conversation is an opportunity to create 😉 something memorable. So why settle for 💓 ordinary when you can communicate with 😾 color, emotion, and life? Embrace the 😉 power of TextEmojiFusion and watch⌚ your 💩 digital interactions blossom🌼 into engaging, expressive, 😾 and extraordinary exchanges. 😽\",\n",
       "   'Positive']],)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spicy=predict([text])\n",
    "spicy"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5529204,
     "sourceId": 9252735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
